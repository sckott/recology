<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Ropensci on Recology</title>
    <link>http://localhost:1313/tags/ropensci/</link>
    <description>Recent content in Ropensci on Recology</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Oct 2015 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ropensci/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Metrics for open source projects</title>
      <link>http://localhost:1313/2015/10/open-source-metrics/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2015/10/open-source-metrics/</guid>
      <description>Measuring use of open source software isn&amp;rsquo;t always straightforward. The problem is especially acute for software targeted largely at academia, where usage is not measured just by software downloads, but also by citations.
Citations are a well-known pain point because the citation graph is privately held by iron doors (e.g., Scopus, Google Scholar). New ventures aim to open up citation data, but of course it&amp;rsquo;s an immense amount of work, and so does not come quickly.</description>
    </item>
    <item>
      <title>Stashing and playing with raw data locally from the web</title>
      <link>http://localhost:1313/2013/06/couch/</link>
      <pubDate>Mon, 17 Jun 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/06/couch/</guid>
      <description>It is getting easier to get data directly into R from the web. Often R packages that retrieve data from the web return useful R data structures to users like a data.frame. This is a good thing of course to make things user friendly.
However, what if you want to drill down into the data that&amp;rsquo;s returned from a query to a database in R? What if you want to get that nice data.</description>
    </item>
    <item>
      <title>BISON USGS species occurrence data</title>
      <link>http://localhost:1313/2013/05/rbison/</link>
      <pubDate>Mon, 27 May 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/05/rbison/</guid>
      <description>The USGS recently released a way to search for and get species occurrence records for the USA. The service is called BISON (Biodiversity Information Serving Our Nation). The service has a web interface for human interaction in a browser, and two APIs (application programming interface) to allow machines to interact with their database. One of the APIs allows you to search and retrieve data, and the other gives back maps as either a heatmap or a species occurrence map.</description>
    </item>
    <item>
      <title>Scholarly metadata in R</title>
      <link>http://localhost:1313/2013/03/r-metadata/</link>
      <pubDate>Sat, 16 Mar 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/03/r-metadata/</guid>
      <description>Scholarly metadata - the meta-information surrounding articles - can be super useful. Although metadata does not contain the full content of articles, it contains a lot of useful information, including title, authors, abstract, URL to the article, etc.
One of the largest sources of metadata is provided via the Open Archives Initiative Protocol for Metadata Harvesting or OAI-PMH. Many publishers, provide their metadata through their own endpoint, and implement the standard OAI-PMH methods: GetRecord, Identify, ListIdentifiers, ListMetadataFormats, ListRecords, and ListSets.</description>
    </item>
    <item>
      <title>Visualizing rOpenSci collaboration</title>
      <link>http://localhost:1313/2013/03/ropensci-collaboration/</link>
      <pubDate>Fri, 08 Mar 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/03/ropensci-collaboration/</guid>
      <description>We (rOpenSci) have been writing code for R packages for a couple years, so it is time to take a look back at the data. What data you ask? The commits data from GitHub ~ data that records who did what and when.
Using the Github commits API we can gather data on who commited code to a Github repository, and when they did it. Then we can visualize this hitorical record.</description>
    </item>
    <item>
      <title>Waiting for an API request to complete</title>
      <link>http://localhost:1313/2013/01/api-token/</link>
      <pubDate>Sat, 26 Jan 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/01/api-token/</guid>
      <description>Dealing with API tokens in R In my previous post I showed an example of calling the Phylotastic taxonomic name resolution API Taxosaurus here. When you query their API they give you a token which you use later to retrieve the result (see examples on their page above). However, you don&amp;rsquo;t know when the query will be done, so how do we know when to send the query to rerieve the data?</description>
    </item>
    <item>
      <title>Resolving species names when you have a lot of them</title>
      <link>http://localhost:1313/2013/01/tnrs-use-case/</link>
      <pubDate>Fri, 25 Jan 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/01/tnrs-use-case/</guid>
      <description>taxize use case: Resolving species names when you have a lot of them Species names can be a pain in the ass, especially if you are an ecologist. We ecologists aren&amp;rsquo;t trained in taxonomy, yet we often end up with huge species lists. Of course we want to correct any spelling errors in the names, and get the newest names for our species, resolve any synonyms, etc.
We are building tools into our R package taxize, that will let you check your species names to make sure they are correct.</description>
    </item>
    <item>
      <title>Open Science Challenge</title>
      <link>http://localhost:1313/2013/01/open-science-challenge/</link>
      <pubDate>Tue, 08 Jan 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2013/01/open-science-challenge/</guid>
      <description>Open Science Science is becoming more open in many areas: publishing, data sharing, lab notebooks, and software. There are many benefits to open science. For example, sharing research data alongside your publications leads to increased citation rate (Piwowar et. al. 2007). In addition, data is becoming easier to share and reuse thanks to efforts like FigShare and Dryad.
If you don&amp;rsquo;t understand the problem we are currently facing due to lack of open science, watch this video:</description>
    </item>
    <item>
      <title>Is invasive?</title>
      <link>http://localhost:1313/2012/12/is-invasive/</link>
      <pubDate>Thu, 13 Dec 2012 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2012/12/is-invasive/</guid>
      <description>The Global Invasive Species Database (GISD) (see their website for more info here) has data on the invasiveness status of many species. From taxize you can now query the GISD database.
Introducing the function gisd_isinvasive. This function was contributed to taxize by Ignasi Bartomeus, a postdoc at the Swedish University Agricultural Sciences.
There are two possible outputs from using gisd_isinvasive: &amp;ldquo;Invasive&amp;rdquo; or &amp;ldquo;Not in GISD&amp;rdquo;. If you use simplify=TRUE in the function you get &amp;ldquo;Invasive&amp;rdquo; or &amp;ldquo;Not in GISD&amp;rdquo;, but if you use simplify=FALSE you get verbose description of the invasive species instead of just &amp;ldquo;Invasive&amp;rdquo; (and you still just get &amp;ldquo;Not in GISD&amp;rdquo;).</description>
    </item>
    <item>
      <title>Shiny apps are awesome</title>
      <link>http://localhost:1313/2012/12/shiny-r/</link>
      <pubDate>Mon, 10 Dec 2012 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2012/12/shiny-r/</guid>
      <description>RStudio has a new product called Shiny that, quoting from their website, &amp;ldquo;makes it super simple for R users like you to turn analyses into interactive web applications that anyone can use&amp;rdquo;. See here for more information.
A Shiny basically consists of two files: a ui.r file and a server.r file. The ui.r file, as it says, provides the user interface, and the server.r file provides the the server logic.</description>
    </item>
  </channel>
</rss>
