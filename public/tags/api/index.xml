<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>API on Recology</title>
    <link>http://localhost:1313/tags/api/</link>
    <description>Recent content in API on Recology</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 Nov 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/api/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mocking HTTP redirects</title>
      <link>http://localhost:1313/2021/11/mocking-redirects/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2021/11/mocking-redirects/</guid>
      <description>You&amp;rsquo;ve experienced an HTTP redirect (or URL redirect, or URL forwarding) even if you haven&amp;rsquo;t noticed. We all use browsers (I assume, since you are reading this), either on a phone or laptop/desktop computer. Browsers don&amp;rsquo;t show all the HTTP requests going on in the background, some of which are redirects. Redirection is used for various reasons, including to prevent broken links when web pages are moved, for privacy protection, to allow multiple domains to refer to a single web page, and more.</description>
    </item>
    <item>
      <title>text mining, apis, and parsing api logs</title>
      <link>http://localhost:1313/2019/03/apis-text-mining-logs/</link>
      <pubDate>Thu, 21 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/03/apis-text-mining-logs/</guid>
      <description>Acquiring full text articles fulltext is an R package I maintain to obtain full text versions of research articles for text mining.
It&amp;rsquo;s a hard problem, with a spaghetti web of code. One of the hard problems is figuring out what the URL is for the full text version of an article. Publishers do not have consistent URL patterns through time, and so you can not set rules once and never revisit them.</description>
    </item>
    <item>
      <title>Exceptions in control flow in R</title>
      <link>http://localhost:1313/2019/03/control-flow-exceptions/</link>
      <pubDate>Mon, 04 Mar 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2019/03/control-flow-exceptions/</guid>
      <description>I was listening to a Bike Shed podcast episode 189, &amp;ldquo;It&amp;rsquo;s Gonna Work, Definitely, No Problems Whatsoever&amp;rdquo;, and starting at 27:44 there was a conversation about exception handling. Specifically it was about exception handling in control flow when doing web API requests. This topic piqued my interest straight away as I do a lot of API stuff (making and wrapping).
The part of the conversation that I want to address is their conclusion that exceptions in control flow are an anti-pattern.</description>
    </item>
    <item>
      <title>Web APIs with Sinatra, Mongo, Docker, and Caddy</title>
      <link>http://localhost:1313/2017/11/sinatra-mongo-docker-caddy/</link>
      <pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2017/11/sinatra-mongo-docker-caddy/</guid>
      <description>The problem The R community has a package distribution thing called CRAN just like Ruby has Rubygems, and Python has Pypi, etc. On all packages on CRAN, the CRAN maintainers run checks on each package on multiple versions of R and on many operating systems. They report those results on a page associated with the package, like this one.
You might be thinking: okay, but we have Travis-CI and friends, so who cares about that?</description>
    </item>
    <item>
      <title>cranchecks: an API for CRAN check results</title>
      <link>http://localhost:1313/2017/09/cranchecks-api/</link>
      <pubDate>Wed, 27 Sep 2017 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2017/09/cranchecks-api/</guid>
      <description>If you maintain an R package, or even use R packages, you may have looked at CRAN check results. These are essentially the results of running R CMD CHECK on a package. They do these for each package for each of a few different operating systems (debian, fedora, solaris, windows, osx) and different R versions (devel, release and patched).
src: https://github.com/ropensci/cchecksapi base api url: https://cranchecks.info CRAN maintainers look at these, and eventually will email maintainers if checks are bad enough.</description>
    </item>
    <item>
      <title>USDA plants database API in R</title>
      <link>http://localhost:1313/2016/10/usda-plants-database-r/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2016/10/usda-plants-database-r/</guid>
      <description>The USDA maintains a database of plant information, some of it trait data, some of it life history. Check it out at https://plants.usda.gov/java/
They&amp;rsquo;ve been talking about releasing an API for a long time, but have not done so.
Thus, since at least some version of their data is in the public web, I&amp;rsquo;ve created a RESTful API for the data:
source code: https://github.com/sckott/usdaplantsapi/ base URL: https://plantsdb.xyz Check out the API, and open issues for bugs/feature requests in the github repo.</description>
    </item>
    <item>
      <title>gbids - GenBank IDs API is back up!</title>
      <link>http://localhost:1313/2016/09/gbids-is-back/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2016/09/gbids-is-back/</guid>
      <description>GBIDS API is back Back in March this year I wrote a post about a new API for working with GenBank IDs.
I had to take the API down because it was too expensive to keep up. Expensive because the dump of data is very large (3.8 GB compressed), and I need disk space on the server to uncompress that to I think about 18 GB, then load into MySQL, which is another maybe 30 GB or so.</description>
    </item>
    <item>
      <title>GenBank IDs API - get, match, swap id types</title>
      <link>http://localhost:1313/2016/03/genbank-ids/</link>
      <pubDate>Tue, 29 Mar 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2016/03/genbank-ids/</guid>
      <description>GenBank IDs, accession numbers and GI identifiers, are the two types of identifiers for entries in GenBank. (see this page for why there are two types of identifiers). Actually, recent news from NCBI is that GI identifiers will be phased out by September this year, which affects what I&amp;rsquo;ll talk about below.
There are a lot of sequences in GenBank. Sometimes you have identifiers and you want to check if they exist in GenBank, or want to get one type from another (accession from GI, or vice versa; although GI phase out will make this use case no longer needed), or just get a bunch of identifiers for software testing purposes perhaps.</description>
    </item>
    <item>
      <title>request - a high level HTTP client for R</title>
      <link>http://localhost:1313/2016/01/request-hello-world/</link>
      <pubDate>Tue, 05 Jan 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2016/01/request-hello-world/</guid>
      <description>request is DSL for http requests for R, and is inspired by the CLI tool httpie. It&amp;rsquo;s built on httr.
The following were driving principles for this package:
The web is increasingly a JSON world, so we assume applications/json by default, but give back other types if not The workflow follows logically, or at least should, from, hey, I got this url, to i need to add some options, to execute request - and functions support piping so that you can execute functions in this order Whenever possible, we transform output to data.</description>
    </item>
    <item>
      <title>noaa - Integrated Surface Database data</title>
      <link>http://localhost:1313/2015/10/noaa-isd/</link>
      <pubDate>Wed, 21 Oct 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/2015/10/noaa-isd/</guid>
      <description>I&amp;rsquo;ve recently made some improvements to the functions that work with ISD (Integrated Surface Database) data.
isd data
The isd() function now caches more intelligently. We now cache using .rds files via saveRDS/readRDS, whereas we used to use .csv files, which take up much more disk space, and we have to worry about not changing data formats on reading data back into an R session. This has the downside that you can&amp;rsquo;t just go directly to open up a cached file in your favorite spreadsheet viewer, but you can do that manually after reading in to R.</description>
    </item>
  </channel>
</rss>
